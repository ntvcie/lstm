import streamlit as st
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler,RobustScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, LayerNormalization
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import os
import mysql.connector
from datetime import timedelta
import joblib
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import plotly.graph_objects as go
import streamlit as st
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, LayerNormalization, SimpleRNN
from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization as TransformerLayerNorm
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention
from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Flatten
from tensorflow.keras.layers import (
    Input, Dense, Dropout, LayerNormalization, MultiHeadAttention,
    GlobalAveragePooling1D, Add
)
import tensorflow as tf
from tensorflow.keras.layers import Conv1D
# Giao di·ªán Streamlit
hide_st_style = """
<style>
    .block-container {
        padding-top: 0rem;  /* Gi·∫£m kho·∫£ng c√°ch ph√≠a tr√™n */
        padding-left: 1rem;
    }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stButton > button {
        width: 100%; /* Chi·ªÅu r·ªông b·∫±ng 100% c·ªßa sidebar */
    }
</style>
"""
st.set_page_config(
    page_title="D·ª± b√°o v·ªõi Multi-Step LSTM",
    layout="wide",
    page_icon="‚úÖ",
    initial_sidebar_state="expanded",
)

#st.markdown("<h1 style='color:#5192e0;'>üíªPh√¢n t√≠ch d·ªØ li·ªáu than t·ª± ch√°y m·ªè h·∫ßm l√≤</h1>", unsafe_allow_html=True)
st.markdown(hide_st_style, unsafe_allow_html=True)
# Main content
# Sidebar ƒë·ªÉ nh·∫≠p th√¥ng tin
with st.sidebar.expander("üíæ C√†i ƒë·∫∑t k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu", expanded=False):
    #st.title("‚öôÔ∏è C√†i ƒë·∫∑t")
    db_host = st.text_input("Host", value="123.24.206.17")
    db_port = st.text_input("Port", value="3306")
    db_user = st.text_input("User", value="admin")
    db_password = st.text_input("Password", value="elatec123!", type="password")
    db_name = st.text_input("Database", value="thantuchay")

# H√†m chu·∫©n h√≥a d·ªØ li·ªáu

scaler_type = st.sidebar.selectbox(
    "üîÑ Ch·ªçn ph∆∞∆°ng ph√°p chu·∫©n h√≥a",
    ["StandardScaler", "MinMaxScaler", "RobustScaler"],
    help="üìå RobustScaler: X·ª≠ l√Ω d·ªØ li·ªáu c√≥ ngo·∫°i lai t·ªët.\nüìå MinMaxScaler: Chu·∫©n h√≥a v·ªÅ [0,1].\nüìå StandardScaler: ƒê∆∞a d·ªØ li·ªáu v·ªÅ ph√¢n ph·ªëi chu·∫©n (mean=0, std=1)."
)
# T·∫°o sidebar ƒë·ªÉ ch·ªçn m√¥ h√¨nh
model_type = st.sidebar.selectbox(
    "Ch·ªçn m√¥ h√¨nh:",
    ["LSTM", "GRU", "SimpleRNN", "Transformer"]
)
with st.sidebar.expander("üè∑Ô∏è Ch·ªçn th√¥ng s·ªë v√† x·ª≠ l√Ω",expanded=True):
    # Sidebar ƒë·ªÉ nh·∫≠p th√¥ng tin
    # selected_parameter = st.selectbox("Ch·ªçn th√¥ng s·ªë ƒë·ªÉ hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o",
    #                                   ["NhietDo1Tram1", "NhietDo2Tram1", "NhietDo1Tram2", "NhietDo2Tram2", "Co1Tram1",
    #                                    "Co2Tram1", "Co1Tram2", "Co2Tram2", "Oxy1Tram1", "Oxy2Tram1", "Oxy1Tram2",
    #                                    "Oxy2Tram2"])
    selected_parameter = st.selectbox("Ch·ªçn th√¥ng s·ªë ƒë·ªÉ hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o",
                                      ["NhietDo1Tram1", "NhietDo2Tram1", "NhietDo1Tram2", "NhietDo2Tram2"])
    LoadProcessDataButton = st.button(
            "‚≠ï T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω",
            #help=f"üìå B∆∞·ªõc 1: Nh·∫•n n√∫t n√†y ƒë·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu v√† t√≠nh to√°n gi√° tr·ªã trung b√¨nh, max, min c·ªßa t·∫≠p d·ªØ li·ªáu v·ªõi th√¥ng s·ªë {selected_parameter}"
        )
with st.sidebar.expander("üîÆ Hu·∫•n luy·ªán & D·ª± b√°o l·ªõn nh·∫•t", expanded=True):
    col1, col2 = st.columns([5, 4])  # C·ªôt 1 r·ªông g·∫•p 5/4 l·∫ßn c·ªôt 2
    with col1:
        TrainMax = st.button(f"üõ†Ô∏è Hu·∫•n luy·ªán")
    with col2:
        ForcastMax = st.button(f"üöÄ D·ª± b√°o")

with st.sidebar.expander("üîÆ Hu·∫•n luy·ªán & D·ª± b√°o trung b√¨nh",expanded=True):
    col1, col2 = st.columns([5, 4])  # C·ªôt 1 r·ªông g·∫•p 5/4 l·∫ßn c·ªôt 2
    with col1:
        TrainMean = st.button(f"üèãÔ∏èÔ∏è Hu·∫•n luy·ªán")
    with col2:
        ForcastMean = st.button(f"üéØ D·ª± b√°o")

with st.sidebar.expander("üîÆ Hu·∫•n luy·ªán & D·ª± b√°o nh·ªè nh·∫•t", expanded=True):
    col1, col2 = st.columns([5, 4])  # C·ªôt 1 r·ªông g·∫•p 5/4 l·∫ßn c·ªôt 2
    with col1:
        TrainMin = st.button(f"üîßÔ∏è Hu·∫•n luy·ªán")
    with col2:
        ForcastMin = st.button(f"üìä D·ª± b√°o")

with st.sidebar.expander("‚ÑπÔ∏è H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng",expanded=False):
    st.markdown("""
        **üìå H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:**  
        - **B∆∞·ªõc 1:** Ch·ªçn th√¥ng s·ªë ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh ho·∫∑c ƒë·ªÉ d·ª± b√°o.  
        - **B∆∞·ªõc 2:** Nh·∫•n **"T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω"** ƒë·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu v√† t√≠nh to√°n gi√° tr·ªã **trung b√¨nh, max, min** c·ªßa t·∫≠p d·ªØ li·ªáu v·ªõi th√¥ng s·ªë.  
        - **B∆∞·ªõc 3.1:** Nh·∫•n **"Hu·∫•n luy·ªán m√¥ h√¨nh trung b√¨nh"** ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh d·ª± b√°o gi√° tr·ªã trung b√¨nh t·ª´ng gi·ªù trong 8 gi·ªù ti·∫øp theo. (N·∫øu ƒë√£ hu·∫•n luy·ªán r·ªìi, b·ªè qua b∆∞·ªõc n√†y).  
        - **B∆∞·ªõc 3.2:** Nh·∫•n **"Hu·∫•n luy·ªán m√¥ h√¨nh l·ªõn nh·∫•t"** ƒë·ªÉ d·ª± b√°o gi√° tr·ªã l·ªõn nh·∫•t.  
        - **B∆∞·ªõc 3.3:** Nh·∫•n **"Hu·∫•n luy·ªán m√¥ h√¨nh nh·ªè nh·∫•t"** ƒë·ªÉ d·ª± b√°o gi√° tr·ªã nh·ªè nh·∫•t.  
        - **B∆∞·ªõc 4.1:** Nh·∫•n **"D·ª± b√°o gi√° tr·ªã trung b√¨nh"** ƒë·ªÉ d·ª± b√°o gi√° tr·ªã trung b√¨nh t·ª´ng gi·ªù trong 8 gi·ªù ti·∫øp theo.  
        - **B∆∞·ªõc 4.2:** Nh·∫•n **"D·ª± b√°o gi√° tr·ªã l·ªõn nh·∫•t"** ƒë·ªÉ d·ª± b√°o gi√° tr·ªã l·ªõn nh·∫•t.  
        - **B∆∞·ªõc 4.3:** Nh·∫•n **"D·ª± b√°o gi√° tr·ªã nh·ªè nh·∫•t"** ƒë·ªÉ d·ª± b√°o gi√° tr·ªã nh·ªè nh·∫•t.  
        """)
# H√†m k·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu MySQL v√† ƒë·ªçc d·ªØ li·ªáu
def get_all_data(days_back, selected_columns, host, port, user, password, database):
    try:
        conn = mysql.connector.connect(host=host, port=port, user=user, password=password, database=database)
        unique_columns = list(set(selected_columns))
        columns_str = ', '.join(unique_columns)
        end_date = pd.Timestamp.now().floor('h')
        start_date = end_date - pd.Timedelta(days=days_back)
        start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')
        end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')
        query = f"""
        SELECT {columns_str}
        FROM dulieuhalong
        WHERE date_time BETWEEN '{start_str}' AND '{end_str}'
        ORDER BY date_time ASC
        """
        df = pd.read_sql(query, conn)
        conn.close()
        return df
    except mysql.connector.Error as err:
        st.error(f"L·ªói k·∫øt n·ªëi MySQL: {err}")
        return None

# H√†m t√≠nh gi√° tr·ªã l·ªõn nh·∫•t v√† trung b√¨nh t·ª´ng gi·ªù
def calculate_hourly_stats(df, column):
    df['hour'] = df['date_time'].dt.floor('h')
    hourly_max = df.groupby('hour')[column].max().reset_index()
    hourly_avg = df.groupby('hour')[column].mean().reset_index()
    hourly_min = df.groupby('hour')[column].min().reset_index()
    full_hours = pd.date_range(start=df['hour'].min(), end=df['hour'].max(), freq="1h")
    full_hours_df = pd.DataFrame({'hour': full_hours})
    hourly_max = full_hours_df.merge(hourly_max, on='hour', how='left')
    hourly_avg = full_hours_df.merge(hourly_avg, on='hour', how='left')
    hourly_min = full_hours_df.merge(hourly_min, on='hour', how='left')
    max_value = df[column].max()
    mean_value = df[column].mean()
    min_value = df[column].min()
    hourly_max[column] = hourly_max[column].fillna(max_value)
    hourly_avg[column] = hourly_avg[column].fillna(mean_value)
    hourly_min[column] = hourly_min[column].fillna(min_value)
    return hourly_max, hourly_avg, hourly_min


# --- H√ÄM CHU·∫®N H√ìA D·ªÆ LI·ªÜU ---
def normalize_data(data, scaler_type):
    if scaler_type == "MinMaxScaler":
        scaler = MinMaxScaler(feature_range=(0, 1))
    elif scaler_type == "RobustScaler":
        scaler = RobustScaler()
    else:
        scaler = StandardScaler()

    data_scaled = scaler.fit_transform(data.reshape(-1, 1))
    return data_scaled, scaler

# H√†m t·∫°o chu·ªói d·ªØ li·ªáu ƒë·∫ßu v√†o v√† ƒë·∫ßu ra
def create_dataset(data, n_steps_in, n_steps_out):
    """
    T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán b·∫±ng k·ªπ thu·∫≠t Sliding Window.

    :param data: M·∫£ng d·ªØ li·ªáu 1D ho·∫∑c 2D (c·ªôt th·ªùi gian).
    :param n_steps_in: S·ªë b∆∞·ªõc ƒë·∫ßu v√†o.
    :param n_steps_out: S·ªë b∆∞·ªõc d·ª± b√°o.
    :return: X_train, y_train d·∫°ng numpy arrays.
    """
    X, y = [], []
    for i in range(len(data) - n_steps_in - n_steps_out + 1):
        X.append(data[i:i + n_steps_in])
        y.append(data[i + n_steps_in:i + n_steps_in + n_steps_out])
    return np.array(X), np.array(y)
#B·∫°n c√≥ th·ªÉ th√™m nhi·ªÖu v√†o X_train tr∆∞·ªõc khi ƒë∆∞a v√†o m√¥ h√¨nh b·∫±ng c√°ch s·ª≠ d·ª•ng numpy:
#Ch·ªâ th√™m nhi·ªÖu v√†o ƒë·∫ßu v√†o X_train, kh√¥ng th√™m v√†o y_train v√¨ n√≥ s·∫Ω l√†m sai l·ªách nh√£n ƒë·∫ßu ra.
#B·∫°n c√≥ th·ªÉ th√™m nhi·ªÖu Gaussian v√†o d·ªØ li·ªáu ƒë·∫ßu v√†o (X) ƒë·ªÉ l√†m m√¥ h√¨nh t·ªïng qu√°t h√≥a t·ªët h∆°n.
def add_gaussian_noise(X, mean=0, std=0.01):
    noise = np.random.normal(mean, std, X.shape)
    return X + noise
# H√†m ki·ªÉm tra t√≠nh d·ª´ng c·ªßa d·ªØ li·ªáu
def make_stationary(data):
    stationary_data = np.diff(data, axis=0)
    return stationary_data

# H√†m x√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh LSTM
from tensorflow.keras.callbacks import Callback
# --- Streamlit App ---
#st.title("Bi·ªÉu ƒë·ªì h·ªôi t·ª• c·ªßa m√¥ h√¨nh LSTM")
# Placeholder ƒë·ªÉ c·∫≠p nh·∫≠t bi·ªÉu ƒë·ªì ƒë·ªông
loss_chart = st.empty()

class StreamlitPlotCallback(Callback):
    def __init__(self):
        super().__init__()
        self.losses = []
        self.learning_rates = []
        self.lr_chart = st.empty()
    def on_epoch_end(self, epoch, logs=None):
        if logs is not None:
            self.losses.append(logs['loss'])
        # Gi·∫£m k√≠ch th∆∞·ªõc h√¨nh v·∫Ω
        fig, ax = plt.subplots(figsize=(3.5, 1.5))  # ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc (r·ªông 4 inch, cao 3 inch)
        ax.plot(self.losses, label="MSE", color="blue")
        #ax.plot(self.losses, color="blue")

        # C·ªë ƒë·ªãnh ph·∫°m vi tr·ª•c ho√†nh (x-axis) t·ª´ 0 ƒë·∫øn 200
        ax.set_xlim(0, 500)
        # ƒê·∫∑t ph·∫°m vi tr·ª•c tung (y-axis) b·∫±ng g·∫•p 2 l·∫ßn gi√° tr·ªã loss l·ªõn nh·∫•t
        max_loss = max(self.losses) if self.losses else 1  # Tr√°nh l·ªói n·∫øu losses r·ªóng
        ax.set_ylim(0, max_loss * 1.2)  # G·∫•p 1.2 l·∫ßn gi√° tr·ªã loss l·ªõn nh·∫•t

        ax.set_xlabel("S·ªë l·∫ßn l·∫∑p (Epoch)")
        ax.set_ylabel("Sai s·ªë (MSE)")
        ax.legend()
        # C·∫≠p nh·∫≠t bi·ªÉu ƒë·ªì trong Streamlit
        loss_chart.pyplot(fig)
        #================================================================================
        lr = float(self.model.optimizer.lr.numpy())
        self.learning_rates.append(lr)

        fig, ax = plt.subplots(figsize=(3.5, 1.5))
        ax.plot(self.learning_rates, label="LR", color="purple")

        # C·ªë ƒë·ªãnh ph·∫°m vi tr·ª•c ho√†nh (x-axis) t·ª´ 0 ƒë·∫øn 200
        ax.set_xlim(0, 500)
        # ƒê·∫∑t ph·∫°m vi tr·ª•c tung (y-axis) b·∫±ng g·∫•p 2 l·∫ßn gi√° tr·ªã loss l·ªõn nh·∫•t
        max_learning_rates = max(self.learning_rates) if self.learning_rates else 1  # Tr√°nh l·ªói n·∫øu losses r·ªóng
        ax.set_ylim(0, max_learning_rates * 2)  # G·∫•p 2 l·∫ßn gi√° tr·ªã loss l·ªõn nh·∫•t

        ax.set_xlabel("S·ªë l·∫ßn l·∫∑p (Epoch)")
        ax.set_ylabel("T·ªëc ƒë·ªô h·ªçc (LR)")

        ax.legend()

        self.lr_chart.pyplot(fig)

# Callback t√πy ch·ªânh ƒë·ªÉ in loss sau m·ªói 5 epoch
class PrintLossCallback(Callback):
    def on_epoch_end(self, epoch, logs=None):
        if (epoch + 1) % 5 == 0:  # In loss sau m·ªói 5 epoch
            #st.write(f"Epoch {epoch + 1}: Loss = {logs['loss']:.4f}")
            st.write(f"**Sai s·ªë b√¨nh ph∆∞∆°ng trung b√¨nh gi·ªØa c√°c gi√° tr·ªã ƒë∆∞·ª£c d·ª± ƒëo√°n v√† th·ª±c t·∫ø MSE**: {logs['loss']:.4f}")

# Callback t√πy ch·ªânh ƒë·ªÉ l∆∞u v√† in loss cu·ªëi c√πng
class FinalLossCallback(Callback):
    def on_train_end(self, logs=None):
        # L·∫•y gi√° tr·ªã loss cu·ªëi c√πng t·ª´ logs
        final_loss = logs.get('loss')
        if final_loss is not None:
            # Hi·ªÉn th·ªã MSE
            st.subheader("üöÄ ƒê√°nh gi√° m√¥ h√¨nh")
            st.write(f"‚úÖÔ∏è **Sai s·ªë b√¨nh ph∆∞∆°ng trung b√¨nh gi·ªØa c√°c gi√° tr·ªã ƒë∆∞·ª£c d·ª± ƒëo√°n v√† th·ª±c t·∫ø MSE**: {final_loss:.4f}")
#thay ƒë·ªïi batch size ƒë·ªông trong qu√° tr√¨nh hu·∫•n luy·ªán n·∫øu m√¥ h√¨nh b·ªã m·∫Øc k·∫πt ·ªü c·ª±c ti·ªÉu c·ª•c b·ªô:
#Gi·∫£m batch size khi loss b·ªã k·∫πt
import tensorflow as tf

class DynamicBatchCallback(tf.keras.callbacks.Callback):
    def __init__(self, dataset, min_bs=16, max_bs=128, patience=5):
        super().__init__()
        self.dataset = dataset.unbatch()  # ƒê·∫£m b·∫£o dataset kh√¥ng b·ªã batch s·∫µn
        self.min_bs = min_bs
        self.max_bs = max_bs
        self.patience = patience
        self.wait = 0
        self.prev_loss = float("inf")

        # T·∫°o danh s√°ch c√°c batch size h·ª£p l·ªá (l≈©y th·ª´a c·ªßa 2)
        self.valid_batch_sizes = [2 ** x for x in range(3, 8)]  # [-2, -4, 8, 16, 32, 64, 128]
        self.current_bs_index = self.valid_batch_sizes.index(min(self.valid_batch_sizes))  # B·∫Øt ƒë·∫ßu t·ª´ min_bs

        # Kh·ªüi t·∫°o batch size ban ƒë·∫ßu
        self.current_bs = self.valid_batch_sizes[self.current_bs_index]
        self.dataset = self.dataset.batch(self.current_bs)

    def on_epoch_end(self, epoch, logs=None):
        loss = logs.get("loss")

        if loss is None:
            return

        # ƒêi·ªÅu ch·ªânh batch size d·ª±a tr√™n loss
        if loss > self.prev_loss:  # N·∫øu loss tƒÉng, gi·∫£m batch size
            if self.current_bs_index > 0:  # Ch·ªâ gi·∫£m n·∫øu kh√¥ng ph·∫£i batch size nh·ªè nh·∫•t
                self.current_bs_index -= 1
                new_bs = self.valid_batch_sizes[self.current_bs_index]
                print(f"‚ö†Ô∏è Gi·∫£m batch size xu·ªëng: {new_bs}")
                print(f"‚ö†Ô∏è M·ª•c ƒë√≠ch: Gi·∫£m batch size gi√∫p m√¥ h√¨nh tho√°t kh·ªèi c·ª±c ti·ªÉu c·ª•c b·ªô.")
                self.dataset = self.dataset.unbatch().batch(new_bs)
                self.wait = 0
        else:  # N·∫øu loss gi·∫£m, tƒÉng batch size
            self.wait += 1
            if self.wait >= self.patience:
                if self.current_bs_index < len(
                        self.valid_batch_sizes) - 1:  # Ch·ªâ tƒÉng n·∫øu kh√¥ng ph·∫£i batch size l·ªõn nh·∫•t
                    self.current_bs_index += 1
                    new_bs = self.valid_batch_sizes[self.current_bs_index]
                    print(f"‚úÖ TƒÉng batch size l√™n: {new_bs}")
                    print(f"‚úÖ M·ª•c ƒë√≠ch: Batch size l·ªõn h∆°n gi√∫p m√¥ h√¨nh h·ªçc nhanh h∆°n v√† ·ªïn ƒë·ªãnh h∆°n.")
                    self.dataset = self.dataset.unbatch().batch(new_bs)
                self.wait = 0

        self.prev_loss = loss



# class StreamlitPlotCallback(Callback):
#     def __init__(self):
#         super().__init__()
#         self.losses = []
#
#     def on_epoch_end(self, epoch, logs=None):
#         if logs is not None:
#             self.losses.append(logs['loss'])
#
#         # V·∫Ω l·∫°i bi·ªÉu ƒë·ªì loss
#         fig, ax = plt.subplots()
#         ax.plot(self.losses, label="Loss tr√™n t·∫≠p hu·∫•n luy·ªán", color="blue")
#         ax.set_xlabel("Epoch")
#         ax.set_ylabel("Loss (MSE)")
#         ax.legend()
#
#         # C·∫≠p nh·∫≠t bi·ªÉu ƒë·ªì trong Streamlit
#         loss_chart.pyplot(fig)

# ƒê·ªãnh nghƒ©a Positional Encoding
def positional_encoding(length, d_model):
    pos = np.arange(length)[:, np.newaxis]
    i = np.arange(d_model)[np.newaxis, :]
    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
    angle_rads = pos * angle_rates
    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
    return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)

# ƒê·ªãnh nghƒ©a kh·ªëi Transformer
def transformer_block(x, num_heads, key_dim, ff_dim, dropout_rate=0.1):
    # MultiHeadAttention
    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)
    x1 = Add()([x, attention_output])  # Residual connection
    x1 = LayerNormalization()(x1)

    # Feed-Forward Network
    ffn = Dense(ff_dim, activation="relu")(x1)
    ffn = Dense(key_dim)(ffn)
    x2 = Add()([x1, ffn])  # Residual connection
    x2 = LayerNormalization()(x2)

    return x2

def build_transformer_model(n_steps_in, n_steps_out, num_heads=4, d_model=64, ff_dim=128, num_blocks=4, dropout_rate=0.1): # Th√™m d_model v√†o tham s·ªë
    inputs = Input(shape=(n_steps_in, 1))

    # === THAY ƒê·ªîI: Chi·∫øu input l√™n d_model ===
    x = Dense(d_model, activation='relu')(inputs) # Chi·∫øu input (..., 1) -> (..., d_model)
    x = LayerNormalization()(x) # C√≥ th·ªÉ norm sau khi chi·∫øu

    # === THAY ƒê·ªîI: T√≠nh PE v·ªõi d_model ===
    pos_encoding = positional_encoding(n_steps_in, d_model)
    x = x + pos_encoding
    x = Dropout(dropout_rate)(x) # Th√™m dropout sau PE

    # Th√™m CNN (T√πy ch·ªçn)
    # x = Conv1D(filters=d_model, kernel_size=3, activation="relu", padding="same")(x)
    # x = LayerNormalization()(x) # Norm sau Conv

    # Kh·ªëi Transformer
    for _ in range(num_blocks):
        # Truy·ªÅn d_model v√†o key_dim ho·∫∑c gi·ªØ key_dim ri√™ng bi·ªát n·∫øu mu·ªën
        x = transformer_block(x, num_heads=num_heads, key_dim=d_model, ff_dim=ff_dim, dropout_rate=dropout_rate)

    # Fully connected layers
    x = GlobalAveragePooling1D()(x)
    # x = Flatten()(x) # Th·ª≠ Flatten thay v√¨ GAP
    x = Dense(256, activation="relu")(x)
    x = Dropout(0.2)(x)
    x = Dense(128, activation="relu")(x)
    x = Dropout(0.2)(x)

    # ƒê·∫ßu ra
    outputs = Dense(n_steps_out)(x)

    # X√¢y d·ª±ng m√¥ h√¨nh
    model = Model(inputs, outputs)
    return model

def train_lstm_model(X_train, y_train, n_steps_in, n_steps_out):
    print("X_train shape ((S·ªë m·∫´u, 48, 1)):", X_train.shape)
    print("y_train shape ((S·ªë m·∫´u, 8, 1)):", y_train.shape)
    print("X_train mean:", np.mean(X_train), "std:", np.std(X_train))
    print("y_train mean:", np.mean(y_train), "std:", np.std(y_train))
    print("======================================================Gi·∫£i th√≠ch============================================================")
    print("Gi·∫£ s·ª≠ b·∫°n c√≥ 280 m·∫´u, batch_size=32")
    print("280 : 32 ‚âà 8.75 batch ‚Üí Do s·ªë batch ph·∫£i l√† s·ªë nguy√™n, Keras s·∫Ω t·ª± ƒë·ªông l·∫•y ƒë·ªß 8 batch (256 m·∫´u), batch cu·ªëi ch·ªâ c√≥ 24 m·∫´u.")
    print("V·∫≠y m·ªói epoch s·∫Ω chia d·ªØ li·ªáu th√†nh 9 batch: 8 batch ƒë·∫ßu c√≥ 32 m·∫´u, 1 batch cu·ªëi ch·ªâ c√≥ 24 m·∫´u")
    print("Sau 1 epoch, m√¥ h√¨nh ƒë√£ duy·ªát qua to√†n b·ªô 280 m·∫´u.")
    print("Batch 1: 32 m·∫´u ƒë·∫ßu ti√™n ‚Üí T√≠nh gradient ‚Üí C·∫≠p nh·∫≠t tr·ªçng s·ªë")
    print("Batch 2: 32 m·∫´u ti·∫øp theo ‚Üí T√≠nh gradient ‚Üí C·∫≠p nh·∫≠t tr·ªçng s·ªë")
    print("...")
    print("Batch 9: 24 m·∫´u cu·ªëi c√πng (v√¨ 280 kh√¥ng chia h·∫øt cho 32)")
    print("üí° M·ªói epoch v·∫´n duy·ªát qua to√†n b·ªô d·ªØ li·ªáu, nh∆∞ng theo t·ª´ng ph·∫ßn nh·ªè.")
    print("============================================================================================================================")
    # model = Sequential([
    #     GRU(512, return_sequences=True, input_shape=(n_steps_in, 1)),
    #     BatchNormalization(),  # Thay th·∫ø BatchNormalization b·∫±ng LayerNormalization
    #     Dropout(0.1),  # TƒÉng t·ª∑ l·ªá Dropout
    #     GRU(256, return_sequences=True),  # Th√™m return_sequences=True
    #     BatchNormalization(),
    #     Dropout(0.1),
    #     GRU(128),  # T·∫ßng cu·ªëi c√πng kh√¥ng c·∫ßn return_sequences=True
    #     BatchNormalization(),
    #     Dropout(0.1),
    #     Dense(n_steps_out)  # ƒê·∫£m b·∫£o n_steps_out ph√π h·ª£p v·ªõi b√†i to√°n
    # ])
    if model_type == "Transformer":
        # === THAY ƒê·ªîI: G·ªçi h√†m build Transformer Model ===
        d_model_transformer = 64  # Ch·ªçn embedding dimension
        model = build_transformer_model(
            n_steps_in, n_steps_out,
            num_heads=4,
            d_model=d_model_transformer,
            ff_dim=128,
            num_blocks=2,  # === TH·ª¨ GI·∫¢M S·ªê BLOCK ===
            dropout_rate=0.1
        )
        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)  # Gi·ªØ Adam ƒë·ªÉ ƒë∆°n gi·∫£n
        model.compile(optimizer=optimizer, loss='mse')

    else:
        # C√°c m√¥ h√¨nh kh√°c (LSTM, GRU, SimpleRNN) v·∫´n s·ª≠ d·ª•ng Sequential
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import LSTM, GRU, SimpleRNN

        if model_type == "LSTM":
            model = Sequential([
                LSTM(512, activation='tanh', return_sequences=True, input_shape=(n_steps_in, 1)),
                BatchNormalization(),  # Thay th·∫ø Batch Normalization b·∫±ng Layer Normalization
                Dropout(0.1),
                LSTM(256, activation='tanh', return_sequences=True),
                BatchNormalization(),  # Thay th·∫ø Batch Normalization b·∫±ng Layer Normalization
                Dropout(0.1),
                LSTM(128, activation='tanh'),
                BatchNormalization(),  # Thay th·∫ø Batch Normalization b·∫±ng Layer Normalization
                Dropout(0.1),
                Dense(n_steps_out)
                #relu
            ])

        elif model_type == "GRU":
            model = Sequential([
                GRU(512, return_sequences=True, input_shape=(n_steps_in, 1)),
                BatchNormalization(),  # Thay th·∫ø BatchNormalization b·∫±ng LayerNormalization
                Dropout(0.1),  # TƒÉng t·ª∑ l·ªá Dropout
                GRU(256, return_sequences=True),  # Th√™m return_sequences=True
                BatchNormalization(),
                Dropout(0.1),
                GRU(128),  # T·∫ßng cu·ªëi c√πng kh√¥ng c·∫ßn return_sequences=True
                BatchNormalization(),
                Dropout(0.1),
                Dense(n_steps_out)  # ƒê·∫£m b·∫£o n_steps_out ph√π h·ª£p v·ªõi b√†i to√°n
            ])
        elif model_type == "SimpleRNN":
            model = Sequential([
                SimpleRNN(200, return_sequences=True, input_shape=(n_steps_in, 1)),
                Dropout(0.1),
                SimpleRNN(200, return_sequences=False),
                Dropout(0.1),
                Dense(n_steps_out)  # ƒê·∫£m b·∫£o n_steps_out ph√π h·ª£p v·ªõi b√†i to√°n
            ])
        model.compile(optimizer='adam', loss='mse')

    # Callbacks
    early_stopping = EarlyStopping(
        monitor="loss",
        patience=25,
        restore_best_weights=True,
        verbose=1
    )

    reduce_lr = ReduceLROnPlateau(
        monitor="loss",
        factor=0.05, # S·ªë nh·ªè thif gi·∫£m t·ªëc ƒë·ªô h·ªçc nh·∫π h∆°n
        patience=25,
        verbose=1,
        min_lr=1e-6
    )

    lr_plot_callback = StreamlitPlotCallback()
    #Gi·∫£m batch size khi loss b·ªã k·∫πt
    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(64)


    # Hu·∫•n luy·ªán m√¥ h√¨nh
    model.fit(
        #X_train, y_train,
        train_dataset,
        epochs=500,  # TƒÉng s·ªë epoch
        #batch_size=32,  # TƒÉng batch size
        verbose=0,
        callbacks=[lr_plot_callback, early_stopping, reduce_lr, DynamicBatchCallback(train_dataset)]
    )

    return model
#==============================Ok===================================================
# def train_lstm_model(X_train, y_train, n_steps_in, n_steps_out):
#     model = Sequential([
#         LSTM(256, activation='relu', return_sequences=True, input_shape=(n_steps_in, 1)),
#         BatchNormalization(),  # Thay th·∫ø Batch Normalization b·∫±ng Layer Normalization
#         #Dropout(0.1),
#         LSTM(128, activation='relu', return_sequences=True),
#         BatchNormalization(),  # Thay th·∫ø Batch Normalization b·∫±ng Layer Normalization
#         #Dropout(0.1),
#         LSTM(64, activation='relu'),
#         BatchNormalization(),  # Thay th·∫ø Batch Normalization b·∫±ng Layer Normalization
#         #Dropout(0.1),
#         Dense(n_steps_out)
#     ])
#     # Chu·∫©n h√≥a gradient b·∫±ng c√°ch gi·ªõi h·∫°n gi√° tr·ªã gradient
#     #optimizer = Adam(clipvalue=1.0)  # Gi·ªõi h·∫°n gradient trong kho·∫£ng [-1.0, 1.0]
#     model.compile(optimizer='adam', loss='mse')
#
#     early_stopping = EarlyStopping(
#         monitor="loss",
#         patience=50,  # TƒÉng patience ƒë·ªÉ cho m√¥ h√¨nh h·ªçc l√¢u h∆°n
#         restore_best_weights=True,
#         verbose=1
#     )
#
#     reduce_lr = ReduceLROnPlateau(
#         monitor="loss",
#         factor=0.5,
#         patience=20,  # TƒÉng patience ƒë·ªÉ gi·∫£m learning rate ch·∫≠m h∆°n
#         verbose=1,
#         min_lr=1e-6
#     )
#
#     lr_plot_callback = StreamlitPlotCallback()
#
#     model.fit(
#         X_train, y_train,
#         epochs=200,
#         verbose=0,
#         callbacks=[lr_plot_callback, early_stopping, reduce_lr]
#     )
#
#     return model
#=========================================Ok==========================================================
# def train_lstm_model(X_train, y_train, n_steps_in, n_steps_out):
#     # X√¢y d·ª±ng m√¥ h√¨nh LSTM
#     model = Sequential([
#         LSTM(300, activation='relu', return_sequences=True, input_shape=(n_steps_in, 1)),
#         LSTM(300, activation='relu'),
#         Dense(n_steps_out)
#     ])
#     model.compile(optimizer='adam', loss='mse')
#     # Callback d·ª´ng s·ªõm n·∫øu loss kh√¥ng gi·∫£m sau 10 epoch
#     early_stopping = EarlyStopping(
#         monitor="loss",  # Theo d√µi loss tr√™n t·∫≠p hu·∫•n luy·ªán
#         patience=20,  # D·ª´ng n·∫øu loss kh√¥ng gi·∫£m trong 10 epoch
#         restore_best_weights=True,  # Quay l·∫°i tr·ªçng s·ªë t·ªët nh·∫•t
#         verbose=1
#     )
#
#     # Kh·ªüi t·∫°o callback ƒë·ªÉ v·∫Ω online
#     plot_callback = StreamlitPlotCallback()
#
#     # Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi callback ƒë·ªÉ v·∫Ω online v√† callback ƒë·ªÉ d·ª´ng luy·ªán n·∫øu sao 10 epoch m√† loss kh√¥ng gi·∫£m
#     model.fit(
#         X_train, y_train,
#         epochs=200,
#         verbose=0,  # ·∫®n log ƒë·ªÉ tr√°nh l√†m r·ªëi UI Streamlit
#         callbacks=[plot_callback, early_stopping, FinalLossCallback()]
#     )
#
#
#     #st.success("M√¥ h√¨nh ƒë√£ ho√†n th√†nh hu·∫•n luy·ªán! üöÄ")
#     return model
#=================================Ok====================================================
# def train_lstm_model(X_train, y_train, n_steps_in, n_steps_out):
#     # X√¢y d·ª±ng m√¥ h√¨nh LSTM
#     model = Sequential()
#
#     model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(n_steps_in, 1)))
#     model.add(LSTM(200, activation='relu'))
#     model.add(Dense(n_steps_out))
#     model.compile(optimizer='adam', loss='mse')
#
#     # Hu·∫•n luy·ªán m√¥ h√¨nh v√† l∆∞u l·∫°i history
#     history = model.fit(
#         X_train, y_train,
#         epochs=200,
#         verbose=1
#     )
#
#     # --- Streamlit App ---
#     st.title("Bi·ªÉu ƒë·ªì h·ªôi t·ª• c·ªßa m√¥ h√¨nh LSTM")
#
#     # V·∫Ω bi·ªÉu ƒë·ªì loss
#     st.subheader("Loss theo s·ªë epoch")
#     fig, ax = plt.subplots()
#     ax.plot(history.history['loss'], label="Loss tr√™n t·∫≠p hu·∫•n luy·ªán", color="blue")
#     ax.set_xlabel("Epoch")
#     ax.set_ylabel("Loss (MSE)")
#     ax.legend()
#     st.pyplot(fig)
#
#     # V·∫Ω bi·ªÉu ƒë·ªì Learning Rate n·∫øu c√≥
#     if 'lr' in history.history:
#         st.subheader("Learning Rate theo s·ªë epoch")
#         fig2, ax2 = plt.subplots()
#         ax2.plot(history.history['lr'], label="Learning Rate", color="red")
#         ax2.set_xlabel("Epoch")
#         ax2.set_ylabel("Learning Rate")
#         ax2.legend()
#         st.pyplot(fig2)
#
#     st.write("M√¥ h√¨nh ƒë√£ ho√†n th√†nh hu·∫•n luy·ªán! üöÄ")
#     return model
#=============================Goc========================================================
# def train_lstm_model(X_train, y_train, n_steps_in, n_steps_out):
#     # X√¢y d·ª±ng m√¥ h√¨nh LSTM
#     model = Sequential([
#         LSTM(300, activation='relu', input_shape=(n_steps_in, 1), return_sequences=True),
#         BatchNormalization(),
#         Dropout(0.01),
#         LSTM(200, activation='relu', return_sequences=True),
#         BatchNormalization(),
#         Dropout(0.01),
#         LSTM(100, activation='relu'),
#         BatchNormalization(),
#         Dropout(0.01),
#         Dense(50, activation='relu'),
#         Dense(n_steps_out)
#     ])
#
#     # C·∫•u h√¨nh optimizer v√† loss function
#     optimizer = Adam(learning_rate=0.001)  # Kh·ªüi t·∫°o v·ªõi learning rate cao h∆°n
#
#     model.compile(optimizer=optimizer, loss='mse')
#
#     # Callback: D·ª´ng s·ªõm n·∫øu loss kh√¥ng gi·∫£m sau 10 epoch
#     early_stopping = EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)
#
#     # Callback: Gi·∫£m learning rate n·∫øu loss kh√¥ng c·∫£i thi·ªán sau 5 epoch
#     reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)
#
#     # Hu·∫•n luy·ªán m√¥ h√¨nh v√† l∆∞u l·∫°i history
#     history = model.fit(
#         X_train, y_train,
#         epochs=200,
#         batch_size=32,
#         callbacks=[early_stopping, reduce_lr],
#         verbose=1
#     )
#
#     # --- Streamlit App ---
#     st.title("Bi·ªÉu ƒë·ªì h·ªôi t·ª• c·ªßa m√¥ h√¨nh LSTM")
#
#     # V·∫Ω bi·ªÉu ƒë·ªì loss
#     st.subheader("Loss theo s·ªë epoch")
#     fig, ax = plt.subplots()
#     ax.plot(history.history['loss'], label="Loss tr√™n t·∫≠p hu·∫•n luy·ªán", color="blue")
#     ax.set_xlabel("Epoch")
#     ax.set_ylabel("Loss (MSE)")
#     ax.legend()
#     st.pyplot(fig)
#
#     # V·∫Ω bi·ªÉu ƒë·ªì Learning Rate n·∫øu c√≥
#     if 'lr' in history.history:
#         st.subheader("Learning Rate theo s·ªë epoch")
#         fig2, ax2 = plt.subplots()
#         ax2.plot(history.history['lr'], label="Learning Rate", color="red")
#         ax2.set_xlabel("Epoch")
#         ax2.set_ylabel("Learning Rate")
#         ax2.legend()
#         st.pyplot(fig2)
#
#     st.write("M√¥ h√¨nh ƒë√£ ho√†n th√†nh hu·∫•n luy·ªán! üöÄ")
#     return model

# H√†m l∆∞u m√¥ h√¨nh v√† scaler k√®m th√¥ng s·ªë
def save_model_with_param(model, scaler, parameter):
    model_filename = f"model_{parameter}.h5"
    scaler_filename = f"scaler_{parameter}.pkl"
    model.save(model_filename)
    joblib.dump(scaler, scaler_filename)

# H√†m t·∫£i m√¥ h√¨nh v√† scaler d·ª±a tr√™n th√¥ng s·ªë
def load_model_with_param(parameter):
    model_filename = f"model_{parameter}.h5"
    scaler_filename = f"scaler_{parameter}.pkl"
    if os.path.exists(model_filename) and os.path.exists(scaler_filename):
        model = load_model(model_filename)
        scaler = joblib.load(scaler_filename)
        return model, scaler
    return None, None

# H√†m ƒëi·ªÅn ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu cho c√°c gi·ªù b·ªã thi·∫øu
def fill_missing_hours(df, column, start_time, end_time):
    full_hours = pd.date_range(start=start_time, end=end_time, freq="1h")
    full_hours_df = pd.DataFrame({'hour': full_hours})
    df['hour'] = df['date_time'].dt.floor('h')
    df_filled = full_hours_df.merge(df, on='hour', how='left')
    mean_value = df[column].mean()
    df_filled[column] = df_filled[column].fillna(mean_value)
    return df_filled

# N√∫t nh·∫•n ƒë·ªÉ t·∫£i d·ªØ li·ªáu
daybackdata = 14
if LoadProcessDataButton:
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω..."):
        selected_columns = ["date_time", selected_parameter]
        df_raw = get_all_data(daybackdata, selected_columns, db_host, db_port, db_user, db_password, db_name)
        if df_raw is None or df_raw.empty:
            st.error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x·ª≠ l√Ω!")
            st.stop()
        # T√≠nh to√°n th·ªùi gian b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c
        end_time = pd.Timestamp.now().floor('h')
        start_time = end_time - pd.Timedelta(days=daybackdata)
        # ƒêi·ªÅn ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu cho c√°c gi·ªù b·ªã thi·∫øu
        df_raw = fill_missing_hours(df_raw, selected_parameter, start_time, end_time)
        # T√≠nh gi√° tr·ªã trung b√¨nh v√† l·ªõn nh·∫•t t·ª´ng gi·ªù
        hourly_max, hourly_avg, hourly_min = calculate_hourly_stats(df_raw, selected_parameter)
        st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i v√† x·ª≠ l√Ω th√†nh c√¥ng!")
        # T·∫°o layout v·ªõi hai c·ªôt
        col1, col2, col3 = st.columns([1, 1, 1])
        # B·∫£ng ·ªü c·ªôt b√™n tr√°i
        with col1:
            st.write("B·∫£ng gi√° tr·ªã l·ªõn nh·∫•t t·ª´ng gi·ªù:")
            #st.write(hourly_max.head(18))
            st.dataframe(hourly_max, height=min(800, 35 * len(hourly_max)))  # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh chi·ªÅu cao
        with col2:
            st.write(f"B·∫£ng gi√° tr·ªã trung b√¨nh t·ª´ng gi·ªù: {len(hourly_avg)} m·∫´u.")
            #st.write(hourly_avg.head(18))
            st.dataframe(hourly_avg, height=min(800, 35 * len(hourly_avg)))
        with col3:
            st.write("B·∫£ng gi√° tr·ªã nh·ªè nh·∫•t t·ª´ng gi·ªù:")
            #st.write(hourly_min.head(18))
            st.dataframe(hourly_min, height=min(800, 35 * len(hourly_min)))
        st.session_state.hourly_avg = hourly_avg
        st.session_state.hourly_max = hourly_max
        st.session_state.hourly_min = hourly_min

# Hu·∫•n luy·ªán m√¥ h√¨nh cho gi√° tr·ªã trung b√¨nh
if TrainMean:
    if 'hourly_avg' in st.session_state:
        st.empty()
        with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho gi√° tr·ªã trung b√¨nh c·ªßa {selected_parameter}..."):
            data_avg = st.session_state.hourly_avg[selected_parameter].values
            stationary_avg = make_stationary(data_avg)
            stationary_avg_scaled, scaler_avg = normalize_data(stationary_avg,scaler_type)
            n_steps_in, n_steps_out = 48, 8
            X_avg, y_avg = create_dataset(stationary_avg_scaled, n_steps_in, n_steps_out)
            # Th√™m nhi·ªÖu v√†o X_max
            if selected_parameter == "NhietDo2Tram2":
                X_avg = add_gaussian_noise(X_avg, std=0.035)
            else:
                X_avg = add_gaussian_noise(X_avg, std=0.01)  # ƒêi·ªÅu ch·ªânh std t√πy theo th·ª≠ nghi·ªám. N·∫øu m√¥ h√¨nh kh√¥ng h·ªôi t·ª• t·ªët, h√£y th·ª≠ gi·∫£m std. std=0.01: Nhi·ªÖu nh·∫π std=0.05: Trung b√¨nh std=0.1: Nhi·ªÖu cao (c√≥ th·ªÉ l√†m ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh)
            X_avg = X_avg.reshape((X_avg.shape[0], X_avg.shape[1], 1))
            model_avg = train_lstm_model(X_avg, y_avg, n_steps_in, n_steps_out)
            save_model_with_param(model_avg, scaler_avg, f"avg_{selected_parameter}")
            st.success(f"M√¥ h√¨nh v√† scaler cho gi√° tr·ªã trung b√¨nh c·ªßa {selected_parameter} ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u l·∫°i!")
    else:
        st.warning("Vui l√≤ng nh·∫•n n√∫t T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o.")
# Hu·∫•n luy·ªán m√¥ h√¨nh cho gi√° tr·ªã l·ªõn nh·∫•t
if TrainMax:
    if 'hourly_max' in st.session_state:
        st.empty()
        with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho gi√° tr·ªã l·ªõn nh·∫•t c·ªßa {selected_parameter}..."):
            data_max = st.session_state.hourly_max[selected_parameter].values
            stationary_max = make_stationary(data_max)
            stationary_max_scaled, scaler_max = normalize_data(stationary_max,scaler_type)
            n_steps_in, n_steps_out = 48, 8
            X_max, y_max = create_dataset(stationary_max_scaled, n_steps_in, n_steps_out)
            # Th√™m nhi·ªÖu v√†o X_max
            X_max = add_gaussian_noise(X_max, std=0.01)  # ƒêi·ªÅu ch·ªânh std t√πy theo th·ª≠ nghi·ªám. N·∫øu m√¥ h√¨nh kh√¥ng h·ªôi t·ª• t·ªët, h√£y th·ª≠ gi·∫£m std. std=0.01: Nhi·ªÖu nh·∫π std=0.05: Trung b√¨nh std=0.1: Nhi·ªÖu cao (c√≥ th·ªÉ l√†m ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh)
            X_max = X_max.reshape((X_max.shape[0], X_max.shape[1], 1))
            model_max = train_lstm_model(X_max, y_max, n_steps_in, n_steps_out)
            save_model_with_param(model_max, scaler_max, f"max_{selected_parameter}")
            st.success(f"M√¥ h√¨nh v√† scaler cho gi√° tr·ªã l·ªõn nh·∫•t c·ªßa {selected_parameter} ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u l·∫°i!")
    else:
        st.warning("Vui l√≤ng nh·∫•n n√∫t T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o.")
# Hu·∫•n luy·ªán m√¥ h√¨nh cho gi√° tr·ªã nh·ªè nh·∫•t
if TrainMin:
    if 'hourly_min' in st.session_state:
        st.empty()
        with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho gi√° tr·ªã nh·ªè nh·∫•t c·ªßa {selected_parameter}..."):
            data_min = st.session_state.hourly_min[selected_parameter].values
            stationary_min = make_stationary(data_min)
            stationary_min_scaled, scaler_min = normalize_data(stationary_min,scaler_type)
            n_steps_in, n_steps_out = 48, 8
            X_min, y_min = create_dataset(stationary_min_scaled, n_steps_in, n_steps_out)
            X_min = X_min.reshape((X_min.shape[0], X_min.shape[1], 1))
            model_min = train_lstm_model(X_min, y_min, n_steps_in, n_steps_out)
            save_model_with_param(model_min, scaler_min, f"min_{selected_parameter}")
            st.success(f"M√¥ h√¨nh v√† scaler cho gi√° tr·ªã nh·ªè nh·∫•t c·ªßa {selected_parameter} ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u l·∫°i!")
    else:
        st.warning("Vui l√≤ng nh·∫•n n√∫t T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o.")
import numpy as np
def handle_outliers(data):
    """
    H√†m ki·ªÉm tra v√† x·ª≠ l√Ω gi√° tr·ªã ngo·∫°i l·ªá trong m·∫£ng d·ªØ li·ªáu.
    - Ph√°t hi·ªán gi√° tr·ªã ngo·∫°i l·ªá s·ª≠ d·ª•ng quy t·∫Øc IQR.
    - Thay th·∫ø gi√° tr·ªã ngo·∫°i l·ªá b·∫±ng gi√° tr·ªã trung b√¨nh c·ªßa d·ªØ li·ªáu kh√¥ng ch·ª©a ngo·∫°i l·ªá.

    :param data: M·∫£ng d·ªØ li·ªáu ƒë·∫ßu v√†o (numpy array ho·∫∑c list).
    :return: M·∫£ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.
    """
    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh numpy array n·∫øu ch∆∞a ph·∫£i
    data = np.array(data)

    # T√≠nh to√°n IQR (Interquartile Range)
    Q1 = np.percentile(data, 25)  # Ph·∫ßn v·ªã 25%
    Q3 = np.percentile(data, 75)  # Ph·∫ßn v·ªã 75%
    IQR = Q3 - Q1  # Kho·∫£ng IQR

    # X√°c ƒë·ªãnh ng∆∞·ª°ng d∆∞·ªõi v√† ng∆∞·ª°ng tr√™n
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # T√¨m c√°c gi√° tr·ªã ngo·∫°i l·ªá
    outliers = (data < lower_bound) | (data > upper_bound)

    # T√≠nh gi√° tr·ªã trung b√¨nh c·ªßa d·ªØ li·ªáu kh√¥ng ch·ª©a ngo·∫°i l·ªá
    non_outliers = data[~outliers]
    mean_non_outliers = np.mean(non_outliers) if len(non_outliers) > 0 else np.mean(data)

    # Thay th·∫ø gi√° tr·ªã ngo·∫°i l·ªá b·∫±ng gi√° tr·ªã trung b√¨nh
    data[outliers] = mean_non_outliers

    return data

# D·ª± b√°o gi√° tr·ªã trung b√¨nh
if ForcastMean:
    if 'hourly_avg' in st.session_state:
        st.empty()
        model_avg, scaler_avg = load_model_with_param(f"avg_{selected_parameter}")
        if model_avg is None or scaler_avg is None:
            st.error(f"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ho·∫∑c scaler cho gi√° tr·ªã trung b√¨nh c·ªßa {selected_parameter}!")
            st.stop()
        with st.spinner(f"ƒêang d·ª± b√°o gi√° tr·ªã trung b√¨nh c·ªßa {selected_parameter}..."):
            # L·∫•y d·ªØ li·ªáu cu·ªëi c√πng (49 gi·ªù g·∫ßn nh·∫•t)
            last_49_avg = st.session_state.hourly_avg[selected_parameter].values[-49:]

            # Ki·ªÉm tra v√† x·ª≠ l√Ω gi√° tr·ªã ngo·∫°i l·ªá
            last_49_avg = handle_outliers(last_49_avg)

            original_value = last_49_avg[0]
            last_48_avg_diff = make_stationary(last_49_avg)
            last_48_avg_scaled, _ = normalize_data(last_48_avg_diff,scaler_type)
            if last_48_avg_scaled.shape[0] < 48:
                st.error(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o! K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {last_48_avg_scaled.shape[0]} m·∫´u.")
                st.stop()
            last_48_avg_scaled = last_48_avg_scaled.reshape((1, 48, 1))
            forecast_avg_scaled = model_avg.predict(last_48_avg_scaled)
            forecast_avg_diff = scaler_avg.inverse_transform(forecast_avg_scaled.reshape(-1, 1))
            forecast_avg_real = np.cumsum(forecast_avg_diff.flatten()) + original_value
            last_hour = st.session_state.hourly_avg["hour"].iloc[-1]
            forecast_time = pd.date_range(start=last_hour, periods=9, freq="h")[1:]

            st.title(f"üìä D·ª± b√°o gi√° tr·ªã trung b√¨nh c·ªßa {selected_parameter} trong 8 gi·ªù ti·∫øp theo")

            forecast_df = pd.DataFrame({
                "Th·ªùi gian": forecast_time,
                "Gi√° tr·ªã d·ª± b√°o": forecast_avg_real
            })
            # T·ªï ch·ª©c giao di·ªán th√†nh c√°c tab
            tab1, tab2 = st.tabs(["Bi·ªÉu ƒë·ªì", "B·∫£ng d·ªØ li·ªáu"])

            with tab1:

                # V·∫Ω bi·ªÉu ƒë·ªì v·ªõi Plotly
                fig = go.Figure()

                # Gi√° tr·ªã th·ª±c t·∫ø
                actual_values = st.session_state.hourly_avg[f"{selected_parameter}"].values[-48:]
                actual_time = st.session_state.hourly_avg["hour"].iloc[-48:].values

                # Chuy·ªÉn ƒë·ªïi actual_time th√†nh datetime
                actual_time = pd.to_datetime(actual_time)

                # ƒê·∫£m b·∫£o forecast_time b·∫Øt ƒë·∫ßu ngay sau actual_time[-1]
                if forecast_time[0] != actual_time[-1] + pd.Timedelta(hours=1):
                    forecast_time = pd.date_range(start=actual_time[-1] + pd.Timedelta(hours=1), periods=8, freq="h")

                fig.add_trace(go.Scatter(
                    x=actual_time,
                    y=actual_values,
                    mode='lines+markers',
                    name="Gi√° tr·ªã th·ª±c t·∫ø",
                    line=dict(color="green", dash="dot"),
                    marker=dict(symbol="x")
                ))

                # Gi√° tr·ªã d·ª± b√°o
                fig.add_trace(go.Scatter(
                    x=forecast_time,
                    y=forecast_avg_real,
                    mode='lines+markers',
                    name="D·ª± b√°o",
                    line=dict(color="red", dash="dot"),
                    marker=dict(symbol="circle")
                ))

                # N√©t n·ªëi gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± b√°o
                connection_x = [actual_time[-1], forecast_time[0]]
                connection_y = [actual_values[-1], forecast_avg_real[0]]
                fig.add_trace(go.Scatter(
                    x=connection_x,
                    y=connection_y,
                    mode='lines',
                    name="N·ªëi gi√° tr·ªã",
                    line=dict(color="orange", dash="dot")
                ))

                # C·∫•u h√¨nh layout
                fig.update_layout(
                    title="üìâ Gi√° tr·ªã trung b√¨nh th·ª±c t·∫ø 48 gi·ªù qua v√† gi√° tr·ªã d·ª± b√°o trong 8 gi·ªù ti·∫øp theo",
                    xaxis_title="Th·ªùi gian",
                    yaxis_title="Gi√° tr·ªã trung b√¨nh",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                    hovermode="x unified"
                )
                st.plotly_chart(fig)

            with tab2:
                # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu
                st.write(forecast_df)

            # Hi·ªÉn th·ªã th√¥ng tin th·ªëng k√™
            #st.subheader("üìä Th√¥ng tin th·ªëng k√™ d·ªØ li·ªáu d·ª± b√°o")
            col1, col2, col3, col4, col5 = st.columns(5)

            # 1. Trung b√¨nh
            mean_value = np.mean(forecast_avg_real)
            #col1.metric("Trung b√¨nh", f"{mean_value:.2f} ¬∞C")

            # Th√™m bi·ªÉu ƒë·ªì gauge cho trung b√¨nh
            fig_mean = go.Figure(go.Indicator(
                mode="gauge+number",
                value=mean_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Trung b√¨nh"},
                gauge={
                    'axis': {'range': [None, 60]},  # Ph·∫°m vi nhi·ªát ƒë·ªô t·ªëi ƒëa
                    'bar': {'color': "blue"},
                    'steps': [
                        {'range': [0, 40], 'color': "green"},
                        {'range': [40, 50], 'color': "orange"},
                        {'range': [50, 60], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': mean_value
                    }
                }
            ))
            col1.plotly_chart(fig_mean, use_container_width=True)

            # 2. L·ªõn nh·∫•t
            max_value = np.max(forecast_avg_real)
            #col2.metric("L·ªõn nh·∫•t", f"{max_value:.2f} ¬∞C")

            # Th√™m bi·ªÉu ƒë·ªì gauge cho gi√° tr·ªã l·ªõn nh·∫•t
            fig_max = go.Figure(go.Indicator(
                mode="gauge+number",
                value=max_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "L·ªõn nh·∫•t"},
                gauge={
                    'axis': {'range': [None, 60]},
                    'bar': {'color': "red"},
                    'steps': [
                        {'range': [0, 40], 'color': "green"},
                        {'range': [40, 50], 'color': "orange"},
                        {'range': [50, 60], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': max_value
                    }
                }
            ))
            col2.plotly_chart(fig_max, use_container_width=True)

            # 3. Nh·ªè nh·∫•t
            min_value = np.min(forecast_avg_real)
            #col3.metric("Nh·ªè nh·∫•t", f"{min_value:.2f} ¬∞C")

            # Th√™m bi·ªÉu ƒë·ªì gauge cho gi√° tr·ªã nh·ªè nh·∫•t
            fig_min = go.Figure(go.Indicator(
                mode="gauge+number",
                value=min_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Nh·ªè nh·∫•t"},
                gauge={
                    'axis': {'range': [None, 60]},
                    'bar': {'color': "white"},
                    'steps': [
                        {'range': [0, 40], 'color': "green"},
                        {'range': [40, 50], 'color': "orange"},
                        {'range': [50, 60], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': min_value
                    }
                }
            ))
            col3.plotly_chart(fig_min, use_container_width=True)

            # ƒê√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô
            temperature_changes = np.diff(forecast_avg_real)  # S·ª± thay ƒë·ªïi gi·ªØa c√°c gi·ªù li√™n ti·∫øp

            # T√≠nh t·ª∑ l·ªá tƒÉng/gi·∫£m
            positive_changes = np.sum(temperature_changes > 0)  # S·ªë l·∫ßn tƒÉng
            negative_changes = np.sum(temperature_changes < 0)  # S·ªë l·∫ßn gi·∫£m
            total_changes = len(temperature_changes)

            # Ng∆∞·ª°ng t·ª∑ l·ªá tƒÉng/gi·∫£m (v√≠ d·ª•: > 60%)
            increase_ratio = positive_changes / total_changes if total_changes > 0 else 0
            decrease_ratio = negative_changes / total_changes if total_changes > 0 else 0

            # Hi·ªÉn th·ªã t·ª∑ l·ªá tƒÉng/gi·∫£m
            #st.write(f"üìä T·ª∑ l·ªá tƒÉng: {increase_ratio * 100:.1f}% | T·ª∑ l·ªá gi·∫£m: {decrease_ratio * 100:.1f}%")

            # Bi·ªÉu ƒë·ªì gauge cho t·ª∑ l·ªá tƒÉng
            fig_increase = go.Figure(go.Indicator(
                mode="gauge+number",
                value=increase_ratio * 100,  # Chuy·ªÉn t·ª∑ l·ªá v·ªÅ ph·∫ßn trƒÉm
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "T·ª∑ l·ªá tƒÉng (%)"},
                gauge={
                    'axis': {'range': [None, 100]},  # Ph·∫°m vi t·ª´ 0% ƒë·∫øn 100%
                    'bar': {'color': "blue"},
                    'steps': [
                        {'range': [0, 30], 'color': "green"},  # An to√†n
                        {'range': [30, 60], 'color': "orange"},  # C·∫£nh b√°o
                        {'range': [60, 100], 'color': "red"}  # Nguy hi·ªÉm
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': increase_ratio * 100  # Gi√° tr·ªã hi·ªán t·∫°i
                    }
                }
            ))
            col4.plotly_chart(fig_increase, use_container_width=True)

            # Bi·ªÉu ƒë·ªì gauge cho t·ª∑ l·ªá gi·∫£m
            fig_decrease = go.Figure(go.Indicator(
                mode="gauge+number",
                value=decrease_ratio * 100,  # Chuy·ªÉn t·ª∑ l·ªá v·ªÅ ph·∫ßn trƒÉm
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "T·ª∑ l·ªá gi·∫£m (%)"},
                gauge={
                    'axis': {'range': [None, 100]},  # Ph·∫°m vi t·ª´ 0% ƒë·∫øn 100%
                    'bar': {'color': "blue"},
                    'steps': [
                        {'range': [0, 30], 'color': "red"},  # Nguy hi·ªÉm
                        {'range': [30, 60], 'color': "orange"},  # C·∫£nh b√°o
                        {'range': [60, 100], 'color': "green"}  # An to√†n
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': decrease_ratio * 100  # Gi√° tr·ªã hi·ªán t·∫°i
                    }
                }
            ))
            col5.plotly_chart(fig_decrease, use_container_width=True)

            # ƒê√°nh gi√° m·ª©c ƒë·ªô than t·ª± ch√°y d·ª±a tr√™n xu h∆∞·ªõng v√† ng∆∞·ª°ng
            max_forecast = np.max(forecast_avg_real)

            st.subheader("üî• ƒê√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô v√† m·ª©c ƒë·ªô than t·ª± ch√°y")

            # Tr∆∞·ªùng h·ª£p 1: Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát (> 60%)
            if increase_ratio > 0.8:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát v√† v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y nghi√™m tr·ªçng!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn theo d√µi ch·∫∑t ch·∫Ω.")
                else:
                    st.info(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát nh∆∞ng v·∫´n d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            elif 0.8 > increase_ratio > 0.6:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng nh·∫π v√† v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y, c·∫ßn c√≥ bi·ªán ph√°p ngƒÉn ch·∫∑n!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng nh·∫π v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
                else:
                    st.info(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng nh·∫π nh∆∞ng v·∫´n d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            elif 0.6 >= increase_ratio > 0.5:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng √≠t v√† v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y, c·∫ßn c√≥ bi·ªán ph√°p ngƒÉn ch·∫∑n!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng √≠t v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
                else:
                    st.info(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng √≠t nh∆∞ng v·∫´n d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            # Tr∆∞·ªùng h·ª£p 3: Nhi·ªát ƒë·ªô kh√¥ng c√≥ xu h∆∞·ªõng r√µ r√†ng
            elif 0.5 >= increase_ratio > 0.3:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh·∫π nh∆∞ng v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y nghi√™m tr·ªçng!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh·∫π v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn theo d√µi ch·∫∑t ch·∫Ω.")
                else:
                    st.info("‚ÑπÔ∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh·∫π v√† d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            # Tr∆∞·ªùng h·ª£p 3: Nhi·ªát ƒë·ªô kh√¥ng c√≥ xu h∆∞·ªõng r√µ r√†ng
            else:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh∆∞ng v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y nghi√™m tr·ªçng!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn theo d√µi ch·∫∑t ch·∫Ω.")
                else:
                    st.info("‚ÑπÔ∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m v√† d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            # Ti√™u ƒë·ªÅ ch√≠nh
            st.subheader("üìä Ph∆∞∆°ng ph√°p ƒë√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô v√† m·ª©c ƒë·ªô nguy c∆° than t·ª± ch√°y")
            # 1. M·ª•c ti√™u
            st.subheader("üéØ M·ª•c ti√™u")
            st.markdown("""
            - **ƒê√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô** d·ª±a tr√™n k·∫øt qu·∫£ d·ª± b√°o.
            - **Nh·∫≠n ƒë·ªãnh m·ª©c ƒë·ªô nguy c∆° than t·ª± ch√°y**, gi√∫p ƒë∆∞a ra quy·∫øt ƒë·ªãnh k·ªãp th·ªùi trong khai th√°c than.
            """)
            # Th√™m bi·ªÉu t∆∞·ª£ng v√† m√†u s·∫Øc ƒë·ªÉ tƒÉng t√≠nh tr·ª±c quan
            st.info("üí° M·ª•c ti√™u ch√≠nh: Ph√°t hi·ªán s·ªõm nguy c∆° than t·ª± ch√°y th√¥ng qua xu h∆∞·ªõng nhi·ªát ƒë·ªô.")
            # 2. Ph∆∞∆°ng ph√°p lu·∫≠n
            st.subheader("üìö Ph∆∞∆°ng ph√°p lu·∫≠n")
            with st.expander("üîç Chi ti·∫øt ph∆∞∆°ng ph√°p"):
                st.subheader("B∆∞·ªõc 1: T√≠nh to√°n s·ª± thay ƒë·ªïi nhi·ªát ƒë·ªô gi·ªØa c√°c gi·ªù li√™n ti·∫øp")
                st.markdown("""
                - S·ª≠ d·ª•ng **sai ph√¢n** (`np.diff`) ƒë·ªÉ t√≠nh s·ª± thay ƒë·ªïi nhi·ªát ƒë·ªô gi·ªØa c√°c gi·ªù li√™n ti·∫øp.
                - K·∫øt qu·∫£ l√† m·ªôt m·∫£ng m·ªõi ch·ª©a s·ª± ch√™nh l·ªách gi·ªØa c√°c gi√° tr·ªã li√™n ti·∫øp.
                """)
                st.subheader("B∆∞·ªõc 2: ƒê√°nh gi√° xu h∆∞·ªõng d·ª±a tr√™n ph·∫ßn trƒÉm thay ƒë·ªïi")
                st.markdown("""
                - N·∫øu **> 70%** c√°c gi√° tr·ªã c√≥ xu h∆∞·ªõng tƒÉng/gi·∫£m, k·∫øt lu·∫≠n r·∫±ng nhi·ªát ƒë·ªô ƒëang c√≥ xu h∆∞·ªõng t∆∞∆°ng ·ª©ng.
                - Ph∆∞∆°ng ph√°p n√†y ph√π h·ª£p v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø, n∆°i m√† nhi·ªát ƒë·ªô th∆∞·ªùng c√≥ bi·∫øn ƒë·ªông nh·ªè xen k·∫Ω.
                """)
                st.subheader("B∆∞·ªõc 3: Ph√¢n lo·∫°i v√† th√¥ng b√°o d·ª±a tr√™n xu h∆∞·ªõng")
                st.markdown("""
                - **TƒÉng r√µ r·ªát (> 70%):** C·∫£nh b√°o nguy c∆° than t·ª± ch√°y gia tƒÉng üî•.
                - **Gi·∫£m r√µ r·ªát (> 70%):** Th√¥ng b√°o t√¨nh tr·∫°ng an to√†n ‚úÖ.
                - **Kh√¥ng r√µ r√†ng:** Y√™u c·∫ßu ti·∫øp t·ª•c theo d√µi ‚ÑπÔ∏è.
                """)
                st.subheader("B∆∞·ªõc 4: K·∫øt h·ª£p v·ªõi ng∆∞·ª°ng nhi·ªát ƒë·ªô")
                st.markdown("""
                - **Ng∆∞·ª°ng th·∫•p:** 40¬∞C üü¢.
                - **Ng∆∞·ª°ng cao:** 50¬∞C üî¥.
                - K·∫øt h·ª£p xu h∆∞·ªõng nhi·ªát ƒë·ªô v·ªõi c√°c ng∆∞·ª°ng ƒë·ªÉ nh·∫≠n ƒë·ªãnh t√¨nh tr·∫°ng than t·ª± ch√°y.
                """)
            # 3. C∆° s·ªü khoa h·ªçc
            st.subheader("üî¨ C∆° s·ªü khoa h·ªçc")
            with st.expander("üìñ Chi ti·∫øt c∆° s·ªü khoa h·ªçc"):
                st.markdown("""
                - **Nhi·ªát ƒë·ªô tƒÉng:** Khi nhi·ªát ƒë·ªô tƒÉng li√™n t·ª•c, ph·∫£n √°nh qu√° tr√¨nh oxy h√≥a than di·ªÖn ra m·∫°nh m·∫Ω, d·∫´n ƒë·∫øn nguy c∆° t·ª± ch√°y üî•.
                - **Nhi·ªát ƒë·ªô gi·∫£m:** Khi nhi·ªát ƒë·ªô gi·∫£m li√™n t·ª•c, cho th·∫•y qu√° tr√¨nh oxy h√≥a b·ªã ki·ªÉm so√°t ho·∫∑c m√¥i tr∆∞·ªùng kh√¥ng thu·∫≠n l·ª£i cho s·ª± t·ª± ch√°y ‚ùÑÔ∏è.
                - **Nhi·ªát ƒë·ªô kh√¥ng ·ªïn ƒë·ªãnh:** S·ª± dao ƒë·ªông nhi·ªát ƒë·ªô c√≥ th·ªÉ do c√°c y·∫øu t·ªë ngo·∫°i c·∫£nh (nh∆∞ thay ƒë·ªïi m√¥i tr∆∞·ªùng, ho·∫°t ƒë·ªông khai th√°c) ho·∫∑c do d·ªØ li·ªáu ch∆∞a ƒë·ªß ch√≠nh x√°c ƒë·ªÉ ƒë∆∞a ra k·∫øt lu·∫≠n ‚ö†Ô∏è.
                - **Ph∆∞∆°ng ph√°p ƒë√°nh gi√° xu h∆∞·ªõng:** D·ª±a tr√™n s·ª± thay ƒë·ªïi li√™n ti·∫øp c·ªßa nhi·ªát ƒë·ªô l√† m·ªôt c√°ch ti·∫øp c·∫≠n ƒë∆°n gi·∫£n nh∆∞ng hi·ªáu qu·∫£.
                - **Xu h∆∞·ªõng tƒÉng/gi·∫£m li√™n t·ª•c:** Cung c·∫•p th√¥ng tin v·ªÅ t√≠nh ·ªïn ƒë·ªãnh c·ªßa h·ªá th·ªëng, gi√∫p ƒë∆∞a ra quy·∫øt ƒë·ªãnh k·ªãp th·ªùi ‚è≥.
                """)
            # 4. ∆Øu ƒëi·ªÉm c·ªßa ph∆∞∆°ng ph√°p
            st.subheader("‚úÖ ∆Øu ƒëi·ªÉm c·ªßa ph∆∞∆°ng ph√°p")
            with st.expander("üåü Chi ti·∫øt ∆∞u ƒëi·ªÉm"):
                st.markdown("""
                - **ƒê∆°n gi·∫£n v√† d·ªÖ hi·ªÉu:** Ch·ªâ s·ª≠ d·ª•ng ph√©p t√≠nh ƒë∆°n gi·∫£n nh∆∞ sai ph√¢n v√† ƒëi·ªÅu ki·ªán logic theo ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh xu h∆∞·ªõng.
                - **Hi·ªáu qu·∫£ trong th·ª±c t·∫ø:** Ph∆∞∆°ng ph√°p n√†y ph√π h·ª£p v·ªõi c√°c h·ªá th·ªëng gi√°m s√°t nhi·ªát ƒë·ªô trong khai th√°c than, n∆°i m√† xu h∆∞·ªõng nhi·ªát ƒë·ªô l√† m·ªôt y·∫øu t·ªë quan tr·ªçng ƒë·ªÉ ƒë√°nh gi√° nguy c∆°.
                - **D·ªÖ t√≠ch h·ª£p v·ªõi giao di·ªán ng∆∞·ªùi d√πng:** C√°c th√¥ng b√°o v√† bi·ªÉu ƒë·ªì tr·ª±c quan gi√∫p ng∆∞·ªùi d√πng nhanh ch√≥ng n·∫Øm b·∫Øt t√¨nh tr·∫°ng.
                """)
    else:
        st.warning("Vui l√≤ng nh·∫•n n√∫t T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o.")
# D·ª± b√°o gi√° tr·ªã l·ªõn nh·∫•t
if ForcastMax:
    if 'hourly_max' in st.session_state:
        st.empty()
        model_max, scaler_max = load_model_with_param(f"max_{selected_parameter}")
        if model_max is None or scaler_max is None:
            st.error(f"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ho·∫∑c scaler cho gi√° tr·ªã l·ªõn nh·∫•t c·ªßa {selected_parameter}!")
            st.stop()
        with st.spinner(f"ƒêang d·ª± b√°o gi√° tr·ªã l·ªõn nh·∫•t c·ªßa {selected_parameter}..."):
            # L·∫•y d·ªØ li·ªáu cu·ªëi c√πng (49 gi·ªù g·∫ßn nh·∫•t)
            last_49_max = st.session_state.hourly_max[selected_parameter].values[-49:]
            print(last_49_max)
            # Ki·ªÉm tra v√† x·ª≠ l√Ω gi√° tr·ªã ngo·∫°i l·ªá
            last_49_max = handle_outliers(last_49_max)

            original_value = last_49_max[0]
            last_48_max_diff = make_stationary(last_49_max)
            last_48_max_scaled, _ = normalize_data(last_48_max_diff, scaler_type)
            if last_48_max_scaled.shape[0] < 48:
                st.error(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o! K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {last_48_max_scaled.shape[0]} m·∫´u.")
                st.stop()
            last_48_max_scaled = last_48_max_scaled.reshape((1, 48, 1))
            forecast_max_scaled = model_max.predict(last_48_max_scaled)
            forecast_max_diff = scaler_max.inverse_transform(forecast_max_scaled.reshape(-1, 1))
            forecast_max_real = np.cumsum(forecast_max_diff.flatten()) + original_value
            last_hour = st.session_state.hourly_max["hour"].iloc[-1]
            forecast_time = pd.date_range(start=last_hour, periods=9, freq="h")[1:]

            st.title(f"üìä D·ª± b√°o gi√° tr·ªã l·ªõn nh·∫•t c·ªßa {selected_parameter} trong 8 gi·ªù ti·∫øp theo")

            forecast_df = pd.DataFrame({
                "Th·ªùi gian": forecast_time,
                "Gi√° tr·ªã d·ª± b√°o": forecast_max_real
            })

            # T·ªï ch·ª©c giao di·ªán th√†nh c√°c tab
            tab1, tab2 = st.tabs(["Bi·ªÉu ƒë·ªì", "B·∫£ng d·ªØ li·ªáu"])

            with tab1:
                # V·∫Ω bi·ªÉu ƒë·ªì v·ªõi Plotly
                fig = go.Figure()

                # Gi√° tr·ªã th·ª±c t·∫ø
                actual_values = st.session_state.hourly_max[f"{selected_parameter}"].values[-48:]
                actual_time = st.session_state.hourly_max["hour"].iloc[-48:].values

                # Chuy·ªÉn ƒë·ªïi actual_time th√†nh datetime
                actual_time = pd.to_datetime(actual_time)

                # ƒê·∫£m b·∫£o forecast_time b·∫Øt ƒë·∫ßu ngay sau actual_time[-1]
                if forecast_time[0] != actual_time[-1] + pd.Timedelta(hours=1):
                    forecast_time = pd.date_range(start=actual_time[-1] + pd.Timedelta(hours=1), periods=8, freq="h")

                fig.add_trace(go.Scatter(
                    x=actual_time,
                    y=actual_values,
                    mode='lines+markers',
                    name="Gi√° tr·ªã th·ª±c t·∫ø",
                    line=dict(color="green", dash="dot"),
                    marker=dict(symbol="x")
                ))

                # Gi√° tr·ªã d·ª± b√°o
                fig.add_trace(go.Scatter(
                    x=forecast_time,
                    y=forecast_max_real,
                    mode='lines+markers',
                    name="D·ª± b√°o",
                    line=dict(color="red", dash="dot"),
                    marker=dict(symbol="circle")
                ))

                # N√©t n·ªëi gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± b√°o
                connection_x = [actual_time[-1], forecast_time[0]]
                connection_y = [actual_values[-1], forecast_max_real[0]]
                fig.add_trace(go.Scatter(
                    x=connection_x,
                    y=connection_y,
                    mode='lines',
                    name="N·ªëi gi√° tr·ªã",
                    line=dict(color="orange", dash="dot")
                ))

                # C·∫•u h√¨nh layout
                fig.update_layout(
                    title="üìâ Gi√° tr·ªã l·ªõn nh·∫•t th·ª±c t·∫ø 48 gi·ªù qua v√† gi√° tr·ªã d·ª± b√°o trong 8 gi·ªù ti·∫øp theo",
                    xaxis_title="Th·ªùi gian",
                    yaxis_title="Gi√° tr·ªã l·ªõn nh·∫•t",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                    hovermode="x unified"
                )

                st.plotly_chart(fig)

            with tab2:
                # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu
                st.write(forecast_df)

            # Hi·ªÉn th·ªã th√¥ng tin th·ªëng k√™
            #st.subheader("üìä Th√¥ng tin th·ªëng k√™ d·ªØ li·ªáu d·ª± b√°o")
            col1, col2, col3, col4, col5 = st.columns(5)

            # 1. Trung b√¨nh
            mean_value = np.mean(forecast_max_real)
            #col1.metric("Trung b√¨nh", f"{mean_value:.2f} ¬∞C")

            # Th√™m bi·ªÉu ƒë·ªì gauge cho trung b√¨nh
            fig_mean = go.Figure(go.Indicator(
                mode="gauge+number",
                value=mean_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Trung b√¨nh"},
                gauge={
                    'axis': {'range': [None, 60]},  # Ph·∫°m vi nhi·ªát ƒë·ªô t·ªëi ƒëa
                    'bar': {'color': "blue"},
                    'steps': [
                        {'range': [0, 40], 'color': "green"},
                        {'range': [40, 50], 'color': "orange"},
                        {'range': [50, 60], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': mean_value
                    }
                }
            ))
            col1.plotly_chart(fig_mean, use_container_width=True)

            # 2. L·ªõn nh·∫•t
            max_value = np.max(forecast_max_real)
            #col2.metric("L·ªõn nh·∫•t", f"{max_value:.2f} ¬∞C")

            # Th√™m bi·ªÉu ƒë·ªì gauge cho gi√° tr·ªã l·ªõn nh·∫•t
            fig_max = go.Figure(go.Indicator(
                mode="gauge+number",
                value=max_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "L·ªõn nh·∫•t"},
                gauge={
                    'axis': {'range': [None, 60]},
                    'bar': {'color': "red"},
                    'steps': [
                        {'range': [0, 40], 'color': "green"},
                        {'range': [40, 50], 'color': "orange"},
                        {'range': [50, 60], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': max_value
                    }
                }
            ))
            col2.plotly_chart(fig_max, use_container_width=True)

            # 3. Nh·ªè nh·∫•t
            min_value = np.min(forecast_max_real)
            #col3.metric("Nh·ªè nh·∫•t", f"{min_value:.2f} ¬∞C")

            # Th√™m bi·ªÉu ƒë·ªì gauge cho gi√° tr·ªã nh·ªè nh·∫•t
            fig_min = go.Figure(go.Indicator(
                mode="gauge+number",
                value=min_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Nh·ªè nh·∫•t"},
                gauge={
                    'axis': {'range': [None, 60]},
                    'bar': {'color': "white"},
                    'steps': [
                        {'range': [0, 40], 'color': "green"},
                        {'range': [40, 50], 'color': "orange"},
                        {'range': [50, 60], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': min_value
                    }
                }
            ))
            col3.plotly_chart(fig_min, use_container_width=True)

            # ƒê√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô
            temperature_changes = np.diff(forecast_max_real)  # S·ª± thay ƒë·ªïi gi·ªØa c√°c gi·ªù li√™n ti·∫øp

            # T√≠nh t·ª∑ l·ªá tƒÉng/gi·∫£m
            positive_changes = np.sum(temperature_changes > 0)  # S·ªë l·∫ßn tƒÉng
            negative_changes = np.sum(temperature_changes < 0)  # S·ªë l·∫ßn gi·∫£m
            total_changes = len(temperature_changes)

            # Ng∆∞·ª°ng t·ª∑ l·ªá tƒÉng/gi·∫£m (v√≠ d·ª•: > 60%)
            increase_ratio = positive_changes / total_changes if total_changes > 0 else 0
            decrease_ratio = negative_changes / total_changes if total_changes > 0 else 0

            # Hi·ªÉn th·ªã t·ª∑ l·ªá tƒÉng/gi·∫£m
            #st.write(f"üìä T·ª∑ l·ªá tƒÉng: {increase_ratio * 100:.1f}% | T·ª∑ l·ªá gi·∫£m: {decrease_ratio * 100:.1f}%")

            # Bi·ªÉu ƒë·ªì gauge cho t·ª∑ l·ªá tƒÉng
            fig_increase = go.Figure(go.Indicator(
                mode="gauge+number",
                value=increase_ratio * 100,  # Chuy·ªÉn t·ª∑ l·ªá v·ªÅ ph·∫ßn trƒÉm
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "T·ª∑ l·ªá tƒÉng (%)"},
                gauge={
                    'axis': {'range': [None, 100]},  # Ph·∫°m vi t·ª´ 0% ƒë·∫øn 100%
                    'bar': {'color': "blue"},
                    'steps': [
                        {'range': [0, 30], 'color': "green"},  # An to√†n
                        {'range': [30, 60], 'color': "orange"},  # C·∫£nh b√°o
                        {'range': [60, 100], 'color': "red"}  # Nguy hi·ªÉm
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': increase_ratio * 100  # Gi√° tr·ªã hi·ªán t·∫°i
                    }
                }
            ))
            col4.plotly_chart(fig_increase, use_container_width=True)

            # Bi·ªÉu ƒë·ªì gauge cho t·ª∑ l·ªá gi·∫£m
            fig_decrease = go.Figure(go.Indicator(
                mode="gauge+number",
                value=decrease_ratio * 100,  # Chuy·ªÉn t·ª∑ l·ªá v·ªÅ ph·∫ßn trƒÉm
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "T·ª∑ l·ªá gi·∫£m (%)"},
                gauge={
                    'axis': {'range': [None, 100]},  # Ph·∫°m vi t·ª´ 0% ƒë·∫øn 100%
                    'bar': {'color': "blue"},
                    'steps': [
                        {'range': [0, 30], 'color': "red"},  # Nguy hi·ªÉm
                        {'range': [30, 60], 'color': "orange"},  # C·∫£nh b√°o
                        {'range': [60, 100], 'color': "green"}  # An to√†n
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': decrease_ratio * 100  # Gi√° tr·ªã hi·ªán t·∫°i
                    }
                }
            ))
            col5.plotly_chart(fig_decrease, use_container_width=True)

            # ƒê√°nh gi√° m·ª©c ƒë·ªô than t·ª± ch√°y d·ª±a tr√™n xu h∆∞·ªõng v√† ng∆∞·ª°ng
            max_forecast = np.max(forecast_max_real)

            st.subheader("üî• ƒê√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô v√† m·ª©c ƒë·ªô than t·ª± ch√°y")

            # Tr∆∞·ªùng h·ª£p 1: Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát (> 60%)
            if increase_ratio >= 0.8:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát v√† v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y nghi√™m tr·ªçng!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn theo d√µi ch·∫∑t ch·∫Ω.")
                else:
                    st.info(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng r√µ r·ªát nh∆∞ng v·∫´n d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            elif 0.8 > increase_ratio > 0.6:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng nh·∫π v√† v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y, c·∫ßn c√≥ bi·ªán ph√°p ngƒÉn ch·∫∑n!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng nh·∫π v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
                else:
                    st.info(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng nh·∫π nh∆∞ng v·∫´n d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            elif 0.6 >= increase_ratio > 0.5:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng √≠t v√† v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y, c·∫ßn c√≥ bi·ªán ph√°p ngƒÉn ch·∫∑n!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng √≠t v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
                else:
                    st.info(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng tƒÉng √≠t nh∆∞ng v·∫´n d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            elif 0.5 >= increase_ratio > 0.3:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh·∫π nh∆∞ng v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y nghi√™m tr·ªçng!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh·∫π v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn theo d√µi ch·∫∑t ch·∫Ω.")
                else:
                    st.info("‚ÑπÔ∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh·∫π v√† d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")
            # Tr∆∞·ªùng h·ª£p 3: Nhi·ªát ƒë·ªô kh√¥ng c√≥ xu h∆∞·ªõng r√µ r√†ng
            else:
                if max_forecast >= 50:
                    st.error(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m nh∆∞ng v∆∞·ª£t ng∆∞·ª°ng cao (>= 50¬∞C). Nguy c∆° than t·ª± ch√°y nghi√™m tr·ªçng!")
                elif 40 <= max_forecast < 50:
                    st.warning(
                        "‚ö†Ô∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m v√† n·∫±m trong kho·∫£ng ng∆∞·ª°ng c·∫£nh b√°o (40¬∞C - 50¬∞C). C·∫ßn theo d√µi ch·∫∑t ch·∫Ω.")
                else:
                    st.info("‚ÑπÔ∏è Nhi·ªát ƒë·ªô c√≥ xu h∆∞·ªõng gi·∫£m v√† d∆∞·ªõi ng∆∞·ª°ng th·∫•p (< 40¬∞C). C·∫ßn ti·∫øp t·ª•c theo d√µi.")

            # Ti√™u ƒë·ªÅ ch√≠nh
            st.subheader("üìä Ph∆∞∆°ng ph√°p ƒë√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô v√† m·ª©c ƒë·ªô nguy c∆° than t·ª± ch√°y")
            # 1. M·ª•c ti√™u
            st.subheader("üéØ M·ª•c ti√™u")
            st.markdown("""
                - **ƒê√°nh gi√° xu h∆∞·ªõng nhi·ªát ƒë·ªô** d·ª±a tr√™n k·∫øt qu·∫£ d·ª± b√°o.
                - **Nh·∫≠n ƒë·ªãnh m·ª©c ƒë·ªô nguy c∆° than t·ª± ch√°y**, gi√∫p ƒë∆∞a ra quy·∫øt ƒë·ªãnh k·ªãp th·ªùi trong khai th√°c than.
                """)
            # Th√™m bi·ªÉu t∆∞·ª£ng v√† m√†u s·∫Øc ƒë·ªÉ tƒÉng t√≠nh tr·ª±c quan
            st.info("üí° M·ª•c ti√™u ch√≠nh: Ph√°t hi·ªán s·ªõm nguy c∆° than t·ª± ch√°y th√¥ng qua xu h∆∞·ªõng nhi·ªát ƒë·ªô.")
            # 2. Ph∆∞∆°ng ph√°p lu·∫≠n
            st.subheader("üìö Ph∆∞∆°ng ph√°p lu·∫≠n")
            with st.expander("üîç Chi ti·∫øt ph∆∞∆°ng ph√°p"):
                st.subheader("B∆∞·ªõc 1: T√≠nh to√°n s·ª± thay ƒë·ªïi nhi·ªát ƒë·ªô gi·ªØa c√°c gi·ªù li√™n ti·∫øp")
                st.markdown("""
                    - S·ª≠ d·ª•ng **sai ph√¢n** ƒë·ªÉ t√≠nh s·ª± thay ƒë·ªïi nhi·ªát ƒë·ªô gi·ªØa c√°c gi·ªù li√™n ti·∫øp.
                    - K·∫øt qu·∫£ l√† m·ªôt m·∫£ng m·ªõi ch·ª©a s·ª± ch√™nh l·ªách gi·ªØa c√°c gi√° tr·ªã li√™n ti·∫øp.
                    """)
                st.subheader("B∆∞·ªõc 2: ƒê√°nh gi√° xu h∆∞·ªõng d·ª±a tr√™n ph·∫ßn trƒÉm thay ƒë·ªïi")
                st.markdown("""
                    - D·ª±a tr√™n ph·∫ßn trƒÉm thay ƒë·ªïi c√°c gi√° tr·ªã c√≥ xu h∆∞·ªõng tƒÉng/gi·∫£m, k·∫øt lu·∫≠n r·∫±ng nhi·ªát ƒë·ªô ƒëang c√≥ xu h∆∞·ªõng t∆∞∆°ng ·ª©ng.
                    - Ph∆∞∆°ng ph√°p n√†y ph√π h·ª£p v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø, n∆°i m√† nhi·ªát ƒë·ªô th∆∞·ªùng c√≥ bi·∫øn ƒë·ªông nh·ªè xen k·∫Ω.
                    """)
                st.subheader("B∆∞·ªõc 3: K·∫øt h·ª£p v·ªõi ng∆∞·ª°ng nhi·ªát ƒë·ªô")
                st.markdown("""
                    - **Ng∆∞·ª°ng th·∫•p:** 40¬∞C üü¢.
                    - **Ng∆∞·ª°ng cao:** 50¬∞C üî¥.
                    - K·∫øt h·ª£p xu h∆∞·ªõng nhi·ªát ƒë·ªô v·ªõi c√°c ng∆∞·ª°ng ƒë·ªÉ nh·∫≠n ƒë·ªãnh t√¨nh tr·∫°ng than t·ª± ch√°y.
                    """)
            # 3. C∆° s·ªü khoa h·ªçc
            st.subheader("üî¨ C∆° s·ªü khoa h·ªçc")
            with st.expander("üìñ Chi ti·∫øt c∆° s·ªü khoa h·ªçc"):
                st.markdown("""
                    - **Nhi·ªát ƒë·ªô tƒÉng:** Khi nhi·ªát ƒë·ªô tƒÉng li√™n t·ª•c, ph·∫£n √°nh qu√° tr√¨nh oxy h√≥a than di·ªÖn ra m·∫°nh m·∫Ω, d·∫´n ƒë·∫øn nguy c∆° t·ª± ch√°y üî•.
                    - **Nhi·ªát ƒë·ªô gi·∫£m:** Khi nhi·ªát ƒë·ªô gi·∫£m li√™n t·ª•c, cho th·∫•y qu√° tr√¨nh oxy h√≥a b·ªã ki·ªÉm so√°t ho·∫∑c m√¥i tr∆∞·ªùng kh√¥ng thu·∫≠n l·ª£i cho s·ª± t·ª± ch√°y ‚ùÑÔ∏è.
                    - **Nhi·ªát ƒë·ªô kh√¥ng ·ªïn ƒë·ªãnh:** S·ª± dao ƒë·ªông nhi·ªát ƒë·ªô c√≥ th·ªÉ do c√°c y·∫øu t·ªë ngo·∫°i c·∫£nh (nh∆∞ thay ƒë·ªïi m√¥i tr∆∞·ªùng, ho·∫°t ƒë·ªông khai th√°c) ho·∫∑c do d·ªØ li·ªáu ch∆∞a ƒë·ªß ch√≠nh x√°c ƒë·ªÉ ƒë∆∞a ra k·∫øt lu·∫≠n ‚ö†Ô∏è.
                    - **Ph∆∞∆°ng ph√°p ƒë√°nh gi√° xu h∆∞·ªõng:** D·ª±a tr√™n s·ª± thay ƒë·ªïi li√™n ti·∫øp c·ªßa nhi·ªát ƒë·ªô l√† m·ªôt c√°ch ti·∫øp c·∫≠n ƒë∆°n gi·∫£n nh∆∞ng hi·ªáu qu·∫£.
                    - **Xu h∆∞·ªõng tƒÉng/gi·∫£m li√™n t·ª•c:** Cung c·∫•p th√¥ng tin v·ªÅ t√≠nh ·ªïn ƒë·ªãnh c·ªßa h·ªá th·ªëng, gi√∫p ƒë∆∞a ra quy·∫øt ƒë·ªãnh k·ªãp th·ªùi ‚è≥.
                    """)
            # 4. ∆Øu ƒëi·ªÉm c·ªßa ph∆∞∆°ng ph√°p
            st.subheader("‚úÖ ∆Øu ƒëi·ªÉm c·ªßa ph∆∞∆°ng ph√°p")
            with st.expander("üåü Chi ti·∫øt ∆∞u ƒëi·ªÉm"):
                st.markdown("""
                    - **ƒê∆°n gi·∫£n v√† d·ªÖ hi·ªÉu:** Ch·ªâ s·ª≠ d·ª•ng ph√©p t√≠nh ƒë∆°n gi·∫£n nh∆∞ sai ph√¢n v√† ƒëi·ªÅu ki·ªán logic theo ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh xu h∆∞·ªõng.
                    - **Hi·ªáu qu·∫£ trong th·ª±c t·∫ø:** Ph∆∞∆°ng ph√°p n√†y ph√π h·ª£p v·ªõi c√°c h·ªá th·ªëng gi√°m s√°t nhi·ªát ƒë·ªô trong khai th√°c than, n∆°i m√† xu h∆∞·ªõng nhi·ªát ƒë·ªô l√† m·ªôt y·∫øu t·ªë quan tr·ªçng ƒë·ªÉ ƒë√°nh gi√° nguy c∆°.
                    - **D·ªÖ t√≠ch h·ª£p v·ªõi giao di·ªán ng∆∞·ªùi d√πng:** C√°c th√¥ng b√°o v√† bi·ªÉu ƒë·ªì tr·ª±c quan gi√∫p ng∆∞·ªùi d√πng nhanh ch√≥ng n·∫Øm b·∫Øt t√¨nh tr·∫°ng.
                    """)
    else:
        st.warning("Vui l√≤ng nh·∫•n n√∫t T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o.")
# D·ª± b√°o gi√° tr·ªã nh·ªè nh·∫•t
if ForcastMin:
    if 'hourly_min' in st.session_state:
        st.empty()
        model_min, scaler_min = load_model_with_param(f"min_{selected_parameter}")
        if model_min is None or scaler_min is None:
            st.error(f"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ho·∫∑c scaler cho gi√° tr·ªã nh·ªè nh·∫•t c·ªßa {selected_parameter}!")
            st.stop()
        with st.spinner(f"ƒêang d·ª± b√°o gi√° tr·ªã nh·ªè nh·∫•t c·ªßa {selected_parameter}..."):
            # L·∫•y d·ªØ li·ªáu cu·ªëi c√πng (49 gi·ªù g·∫ßn nh·∫•t)
            last_49_min = st.session_state.hourly_min[selected_parameter].values[-49:]

            # Ki·ªÉm tra v√† x·ª≠ l√Ω gi√° tr·ªã ngo·∫°i l·ªá
            last_49_min = handle_outliers(last_49_min)

            original_value = last_49_min[0]
            last_48_min_diff = make_stationary(last_49_min)
            last_48_min_scaled, _ = normalize_data(last_48_min_diff,scaler_type)
            if last_48_min_scaled.shape[0] < 48:
                st.error(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o! K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {last_48_min_scaled.shape[0]} m·∫´u.")
                st.stop()
            last_48_min_scaled = last_48_min_scaled.reshape((1, 48, 1))
            forecast_min_scaled = model_min.predict(last_48_min_scaled)
            forecast_min_diff = scaler_min.inverse_transform(forecast_min_scaled.reshape(-1, 1))
            forecast_min_real = np.cumsum(forecast_min_diff.flatten()) + original_value
            last_hour = st.session_state.hourly_min["hour"].iloc[-1]
            forecast_time = pd.date_range(start=last_hour, periods=9, freq="h")[1:]
            st.subheader(f"D·ª± b√°o gi√° tr·ªã nh·ªè nh·∫•t c·ªßa {selected_parameter} trong 8 gi·ªù ti·∫øp theo")
            forecast_df = pd.DataFrame({
                "Th·ªùi gian": forecast_time,
                "Gi√° tr·ªã d·ª± b√°o": forecast_min_real
            })
            # T·ªï ch·ª©c giao di·ªán th√†nh c√°c tab
            tab1, tab2 = st.tabs(["Bi·ªÉu ƒë·ªì", "B·∫£ng d·ªØ li·ªáu"])

            with tab1:
                # V·∫Ω bi·ªÉu ƒë·ªì v·ªõi Plotly
                fig = go.Figure()

                # Gi√° tr·ªã th·ª±c t·∫ø
                actual_values = st.session_state.hourly_min[f"{selected_parameter}"].values[-48:]
                actual_time = st.session_state.hourly_min["hour"].iloc[-48:].values

                fig.add_trace(go.Scatter(
                    x=actual_time,
                    y=actual_values,
                    mode='lines+markers',
                    name="Gi√° tr·ªã th·ª±c t·∫ø",
                    line=dict(color="green", dash="dot"),
                    marker=dict(symbol="x")
                ))

                # Gi√° tr·ªã d·ª± b√°o
                fig.add_trace(go.Scatter(
                    x=forecast_time,
                    y=forecast_min_real,
                    mode='lines+markers',
                    name="D·ª± b√°o",
                    line=dict(color="red"),
                    marker=dict(symbol="circle")
                ))

                # N√©t n·ªëi gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± b√°o
                connection_x = [actual_time[-1], forecast_time[0]]
                connection_y = [actual_values[-1], forecast_min_real[0]]
                fig.add_trace(go.Scatter(
                    x=connection_x,
                    y=connection_y,
                    mode='lines',
                    name="N·ªëi gi√° tr·ªã",
                    line=dict(color="blue", dash="dot")
                ))

                # C·∫•u h√¨nh layout
                fig.update_layout(
                    title="üìâ Gi√° tr·ªã nh·ªè nh·∫•t th·ª±c t·∫ø 48 gi·ªù qua v√† gi√° tr·ªã d·ª± b√°o trong 8 gi·ªù ti·∫øp theo",
                    xaxis_title="Th·ªùi gian",
                    yaxis_title="Gi√° tr·ªã nh·ªè nh·∫•t",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                    hovermode="x unified"
                )

                st.plotly_chart(fig)

            with tab2:
                # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu
                st.write(forecast_df)

            # Hi·ªÉn th·ªã th√¥ng tin th·ªëng k√™
            st.subheader("Th√¥ng tin th·ªëng k√™")
            col1, col2, col3 = st.columns(3)
            col1.metric("Trung b√¨nh", f"{np.mean(forecast_min_real):.2f}")
            col2.metric("L·ªõn nh·∫•t", f"{np.max(forecast_min_real):.2f}")
            col3.metric("Nh·ªè nh·∫•t", f"{np.min(forecast_min_real):.2f}")
            # st.write(forecast_df)
            #
            # # V·∫Ω ƒë·ªì th·ªã
            # plt.figure(figsize=(10, 6))
            #
            # # V·∫Ω gi√° tr·ªã th·ª±c t·∫ø
            # actual_values = st.session_state.hourly_min[f"{selected_parameter}"].values[-48:]
            # actual_time = st.session_state.hourly_min["hour"].iloc[-48:].values  # Chuy·ªÉn ƒë·ªïi th√†nh m·∫£ng NumPy
            #
            # # Ki·ªÉm tra k√≠ch th∆∞·ªõc d·ªØ li·ªáu
            # if len(actual_time) == 0 or len(forecast_time) == 0:
            #     st.error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã!")
            #     st.stop()
            #
            # plt.plot(actual_time, actual_values, label="Gi√° tr·ªã th·ª±c t·∫ø", color="green", linestyle="--", marker="x")
            #
            # # V·∫Ω gi√° tr·ªã d·ª± b√°o
            # plt.plot(forecast_time, forecast_min_real, label="D·ª± b√°o", color="red", marker="o")
            #
            # # N√©t n·ªëi gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± b√°o
            # connection_x = [actual_time[-1], forecast_time[0]]
            # connection_y = [actual_values[-1], forecast_min_real[0]]
            # plt.plot(connection_x, connection_y, color="blue", linestyle=":", linewidth=2, label="N·ªëi gi√° tr·ªã")
            #
            # # ƒê·∫∑t nh√£n tr·ª•c x
            # plt.xlabel("Th·ªùi gian")
            #
            # # ƒê·∫∑t nh√£n tr·ª•c y
            # plt.ylabel("Gi√° tr·ªã nh·ªè nh·∫•t")
            #
            # # ƒê·∫∑t ti√™u ƒë·ªÅ ƒë·ªì th·ªã
            # plt.title("So s√°nh gi√° tr·ªã th·ª±c t·∫ø v√† gi√° tr·ªã d·ª± b√°o trong 8 gi·ªù ti·∫øp theo")
            #
            # # Xoay nh√£n tr·ª•c x ƒë·ªÉ d·ªÖ ƒë·ªçc
            # plt.xticks(rotation=45)
            #
            # # Th√™m ch√∫ th√≠ch
            # plt.legend()
            #
            # # ƒêi·ªÅu ch·ªânh layout ƒë·ªÉ tr√°nh ch·ªìng ch√©o
            # plt.tight_layout()
            #
            # # Hi·ªÉn th·ªã ƒë·ªì th·ªã
            # st.pyplot(plt)
    else:
        st.warning("Vui l√≤ng nh·∫•n n√∫t T·∫£i d·ªØ li·ªáu v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán ho·∫∑c d·ª± b√°o.")